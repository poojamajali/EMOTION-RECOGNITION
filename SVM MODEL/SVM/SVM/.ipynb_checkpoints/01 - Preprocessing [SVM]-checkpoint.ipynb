{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### General imports ###\n",
    "from glob import glob\n",
    "import os\n",
    "import pickle\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "### Audio preprocessing imports ###\n",
    "from AudioLibrary.AudioSignal import *\n",
    "from AudioLibrary.AudioFeatures import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAVDESS Database\n",
    "label_dict_ravdess = {'02': 'NEU', '03':'HAP', '04':'SAD', '05':'ANG', '06':'FEA', '07':'DIS', '08':'SUR'}\n",
    "\n",
    "# Set audio files labels\n",
    "def set_label_ravdess(audio_file, gender_differentiation):\n",
    "    label = label_dict_ravdess.get(audio_file[6:-16])\n",
    "    if gender_differentiation == True:\n",
    "        if int(audio_file[18:-4])%2 == 0: # Female\n",
    "            label = 'f_' + label\n",
    "        if int(audio_file[18:-4])%2 == 1: # Male\n",
    "            label = 'm_' + label\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Data: START\n",
      "D:/EIS/Audio_Speech_Actors_01-24/Actor_01/\n",
      "D:/EIS/Audio_Speech_Actors_01-24/Actor_02/\n",
      "D:/EIS/Audio_Speech_Actors_01-24/Actor_03/\n",
      "D:/EIS/Audio_Speech_Actors_01-24/Actor_04/\n",
      "D:/EIS/Audio_Speech_Actors_01-24/Actor_05/\n",
      "D:/EIS/Audio_Speech_Actors_01-24/Actor_06/\n",
      "D:/EIS/Audio_Speech_Actors_01-24/Actor_07/\n",
      "D:/EIS/Audio_Speech_Actors_01-24/Actor_08/\n",
      "D:/EIS/Audio_Speech_Actors_01-24/Actor_09/\n",
      "D:/EIS/Audio_Speech_Actors_01-24/Actor_10/\n",
      "D:/EIS/Audio_Speech_Actors_01-24/Actor_11/\n",
      "D:/EIS/Audio_Speech_Actors_01-24/Actor_12/\n",
      "D:/EIS/Audio_Speech_Actors_01-24/Actor_13/\n",
      "D:/EIS/Audio_Speech_Actors_01-24/Actor_14/\n",
      "D:/EIS/Audio_Speech_Actors_01-24/Actor_15/\n",
      "D:/EIS/Audio_Speech_Actors_01-24/Actor_16/\n",
      "D:/EIS/Audio_Speech_Actors_01-24/Actor_17/\n",
      "D:/EIS/Audio_Speech_Actors_01-24/Actor_18/\n",
      "D:/EIS/Audio_Speech_Actors_01-24/Actor_19/\n",
      "D:/EIS/Audio_Speech_Actors_01-24/Actor_20/\n",
      "D:/EIS/Audio_Speech_Actors_01-24/Actor_21/\n",
      "D:/EIS/Audio_Speech_Actors_01-24/Actor_22/\n",
      "D:/EIS/Audio_Speech_Actors_01-24/Actor_23/\n",
      "D:/EIS/Audio_Speech_Actors_01-24/Actor_24/\n",
      "Import Data: END \n",
      "\n",
      "Number of audio files imported: 1344\n"
     ]
    }
   ],
   "source": [
    "# Start feature extraction\n",
    "print(\"Import Data: START\")\n",
    "\n",
    "# Audio file path and names\n",
    "file_path = 'D:/EIS/Audio_Speech_Actors_01-24/'\n",
    "file_names = os.listdir(file_path)\n",
    "#print(file_names)\n",
    "# Initialize signal and labels list\n",
    "signal = []\n",
    "labels = []\n",
    "\n",
    "# Sample rate (44.1 kHz)\n",
    "sample_rate = 44100     \n",
    "\n",
    "# Compute global statistics features for all audio file\n",
    "\n",
    "for file_name in file_names:\n",
    "    audio_path=file_path+file_name+'/'    \n",
    "    print(audio_path)\n",
    "    audio_names=os.listdir(audio_path)\n",
    "    #print(audio_names)\n",
    "    #print('*******************************************************************')\n",
    "    for audio_index, audio_file in enumerate(audio_names):\n",
    "        # Select audio file\n",
    "        if audio_file[6:-16] in label_dict_ravdess.keys():\n",
    "\n",
    "            # Read audio file\n",
    "            signal.append(AudioSignal(sample_rate, filename=audio_path + audio_file))\n",
    "\n",
    "            # Set label\n",
    "            labels.append(set_label_ravdess(audio_file, True))\n",
    "\n",
    "            # Print running...\n",
    "            if (audio_index % 100 == 0):\n",
    "                print(\"Import Data: RUNNING ... {} files\".format(audio_index))\n",
    "        \n",
    "# Cast labels to array\n",
    "labels = np.asarray(labels).ravel()\n",
    "\n",
    "# Stop feature extraction\n",
    "print(\"Import Data: END \\n\")\n",
    "print(\"Number of audio files imported: {}\".format(labels.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio features extraction function\n",
    "def global_feature_statistics(y, win_size=0.025, win_step=0.01, nb_mfcc=12, mel_filter=40,\n",
    "                             stats = ['mean', 'std', 'med', 'kurt', 'skew', 'q1', 'q99', 'min', 'max', 'range'],\n",
    "                             features_list =  ['zcr', 'energy', 'energy_entropy', 'spectral_centroid', 'spectral_spread', 'spectral_entropy', 'spectral_flux', 'sprectral_rolloff', 'mfcc']):\n",
    "    \n",
    "    # Extract features\n",
    "    audio_features = AudioFeatures(y, win_size, win_step)\n",
    "    features, features_names = audio_features.global_feature_extraction(stats=stats, features_list=features_list)\n",
    "    return features\n",
    "    \n",
    "# Features extraction parameters\n",
    "sample_rate = 16000 # Sample rate (16.0 kHz)\n",
    "win_size = 0.025    # Short term window size (25 msec)\n",
    "win_step = 0.01     # Short term window step (10 msec)\n",
    "nb_mfcc = 12        # Number of MFCCs coefficients (12)\n",
    "nb_filter = 40      # Number of filter banks (40)\n",
    "stats = ['mean', 'std', 'med', 'kurt', 'skew', 'q1', 'q99', 'min', 'max', 'range'] # Global statistics\n",
    "features_list =  ['zcr', 'energy', 'energy_entropy', 'spectral_centroid', 'spectral_spread', # Audio features\n",
    "                      'spectral_entropy', 'spectral_flux', 'sprectral_rolloff', 'mfcc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction: START\n",
      "Feature extraction: END!\n"
     ]
    }
   ],
   "source": [
    "# Start feature extraction\n",
    "print(\"Feature extraction: START\")\n",
    "\n",
    "# Compute global feature statistics for all audio file\n",
    "features = np.asarray(list(map(global_feature_statistics, signal)))\n",
    "\n",
    "# Stop feature extraction\n",
    "print(\"Feature extraction: END!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to pickle\n",
    "pickle.dump([features, labels], open(\"Pickle/[RAVDESS][HAP-SAD-NEU-ANG-FEA-DIS-SUR][GLOBAL_STATS].p\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
